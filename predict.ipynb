{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predict.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "def remove_back(path):\n",
        "  \"\"\"\n",
        "  Helper Function to remove Background\n",
        "  str: path = path to image\n",
        "  returns: newpath to image without Background\n",
        "  \"\"\"\n",
        "  new_path = \"img.png\"\n",
        "  !backgroundremover -i $path -o $new_path\n",
        "  return new_path\n",
        "\n",
        "\n",
        "def is_camel_black(path):\n",
        "  \"\"\"\"\n",
        "  Checks if camel is black.\n",
        "  path: path to image.\n",
        "  returns: True if Camel is black\n",
        "  \"\"\"\n",
        "  from PIL import Image\n",
        "  import imageio\n",
        "  import os\n",
        "  import numpy as np\n",
        "\n",
        "\n",
        "  # remove background\n",
        "  new_path = remove_back(path)\n",
        "  # Read the created image\n",
        "  img = imageio.imread(new_path, as_gray=True)\n",
        "  # delete created files\n",
        "  os.remove(new_path)\n",
        "  # Get the mean of the image to check if it is black\n",
        "  return np.mean(img) < 20"
      ],
      "metadata": {
        "id": "iYQhBZ1_x4-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_camel(image,is_camel_model):\n",
        "    \"\"\"\"\n",
        "    Checks if the input is a camel.\n",
        "    image: image to check,\n",
        "    is_camel_model: model to check with.\n",
        "    \"\"\"\n",
        "    import tensorflow as tf\n",
        "    # Prepocess input for resnet\n",
        "    image = tf.keras.applications.resnet.preprocess_input(image)\n",
        "    # predict\n",
        "    pred = is_camel_model(image)\n",
        "    # encode prediction\n",
        "    is_camel = tf.keras.applications.resnet.decode_predictions(pred.numpy(), top=1)\n",
        "    return is_camel[0][0][1] == \"Arabian_camel\"\n",
        "    \n"
      ],
      "metadata": {
        "id": "HrVGVd6GVf8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3juRLgoJpRdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c86100c2-9ddf-416b-b320-a92069a1c109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/drive/MyDrive/images_test/vlc_extracted00661-background.png\n",
            "2.3381927\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "/content/drive/MyDrive/images_test/vlc_extracted00651-background.png\n",
            "0.98601913\n",
            "{'/content/drive/MyDrive/images_test/vlc_extracted00651.png': <tf.Tensor: shape=(), dtype=float32, numpy=13.2826>, '/content/drive/MyDrive/images_test/vlc_extracted00661.png': <tf.Tensor: shape=(), dtype=float32, numpy=12.46401>}\n",
            "['/content/drive/MyDrive/images_test/vlc_extracted00651.png', '/content/drive/MyDrive/images_test/vlc_extracted00661.png']\n"
          ]
        }
      ],
      "source": [
        "  def predict(paths, path_to_saved_model):\n",
        "    \"\"\"\"\n",
        "    Ranks camels with with a Neural Network.\n",
        "    paths: paths to images to rank.\n",
        "    returns: paths ordered\n",
        "    \"\"\"\n",
        "    !pip install -q backgroundremover\n",
        "    import numpy as np\n",
        "    import tensorflow as tf\n",
        "    import sys\n",
        "    # Load in models so we do not need to load them in with every image\n",
        "    is_camel_model = tf.keras.applications.resnet.ResNet152()\n",
        "    model_classify = tf.keras.models.load_model(path_to_saved_model)\n",
        "    ordered_dict = dict()\n",
        "    for i, path in enumerate(paths):\n",
        "      # load in image\n",
        "      img = tf.keras.preprocessing.image.load_img(path)\n",
        "      # resize it for out models\n",
        "      img = tf.image.resize(np.array(img), (224,224))\n",
        "      # put None in front for our models\n",
        "      img = img[None,:,:]\n",
        "      # Check if it is a camel\n",
        "      if not is_camel(img, is_camel_model):\n",
        "        print(f\"Image number {i+1} is not a camel and will not be ranked\" )\n",
        "        continue\n",
        "      if not is_camel_black(path):\n",
        "        print(f\"Camel number {i+1} is not black and will not be ranked\" )\n",
        "        continue\n",
        "      # Run the img through the classifier and save the result. The minus has the effect that the first class is worth more\n",
        "      ordered_dict[path] = - model_classify(img)[0][0]\n",
        "    # order the dict\n",
        "    ordered_dict = {k: v for k, v in sorted(ordered_dict.items(), key=lambda item: item[1], reverse = True)}\n",
        "    print(ordered_dict)\n",
        "    return list(ordered_dict.keys())\n",
        "\n",
        "print(predict([\"/content/drive/MyDrive/images_test/vlc_extracted00661.png\", \"/content/drive/MyDrive/images_test/vlc_extracted00651.png\"],\"/content/drive/MyDrive/saved_model/my_model_92%\"))"
      ]
    }
  ]
}